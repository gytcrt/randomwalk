<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Random Walk</title>
    <link>http://localhost:49602/posts/</link>
    <description>Recent content in Posts on Random Walk</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 08 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:49602/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Why Is It Hard To Evaluate GenAI Applications?</title>
      <link>http://localhost:49602/posts/genai-evaluation-challenge/</link>
      <pubDate>Thu, 08 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:49602/posts/genai-evaluation-challenge/</guid>
      <description>&lt;h2 id=&#34;tldr&#34;&gt;TL;DR&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Lack of framework&lt;/strong&gt;: GenAI application is not GenAI foundation model; it requires different framework to evaluate them. People are not clear about the difference between the two tasks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unstructured data&lt;/strong&gt;: Unstructured output of GenAI application makes evaluation more difficult than traditional ML system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Foundation model unpredictability&lt;/strong&gt;: GeanAI foundation model usually brings extra unpredictability into evaluation process.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Longer and more costly iteration&lt;/strong&gt;: GenAI application evaluation is expensive and time consuming, because building evaluation dataset and running tests on GenAI application require more resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I have spent last 2.5 years on listening to what business wants from GenAI, building GenAI applications and delivering value from the applications. It has been interesting journey for me, and I realized the advent of ChatGPT is a paradigm shift for ML/AI practitioners like me. I started believe GenAI would change our lives like personal computer in 90s or modern search engine in 2000s.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h2 id="tldr">TL;DR</h2>
<ul>
<li><strong>Lack of framework</strong>: GenAI application is not GenAI foundation model; it requires different framework to evaluate them. People are not clear about the difference between the two tasks.</li>
<li><strong>Unstructured data</strong>: Unstructured output of GenAI application makes evaluation more difficult than traditional ML system.</li>
<li><strong>Foundation model unpredictability</strong>: GeanAI foundation model usually brings extra unpredictability into evaluation process.</li>
<li><strong>Longer and more costly iteration</strong>: GenAI application evaluation is expensive and time consuming, because building evaluation dataset and running tests on GenAI application require more resources.</li>
</ul>
<h2 id="introduction">Introduction</h2>
<p>I have spent last 2.5 years on listening to what business wants from GenAI, building GenAI applications and delivering value from the applications. It has been interesting journey for me, and I realized the advent of ChatGPT is a paradigm shift for ML/AI practitioners like me. I started believe GenAI would change our lives like personal computer in 90s or modern search engine in 2000s.</p>
<p>Before I dive into evaluation of GenAI, I want to define a few key terms for this article. These terms are used interchangeable and over-used nowadays, but I found it difficult to discuss any AI related topic without clearly defining the scope of these terms. Please find my definition below:</p>
<figure class="align-center">
    <a href="AI-terms.svg" 
       class="glightbox" 
       data-gallery="gallery1" 
       data-title="What AI, ML, GenAI and LLM mean in this article"
       data-type="image"
       data-effect="fade"
       data-zoomable="true">
      <img src="AI-terms.svg" alt="What AI, ML, GenAI and LLM mean in this article">
    </a>
    
      <figcaption>What AI, ML, GenAI and LLM mean in this article</figcaption>
    
  </figure>
  
<p><strong>Essentially, ML is what we are used to and have been evaluating in last decades, and GenAI and LLM are the new technology we want to evaluate against.</strong> AI is a umbrella term for everythingðŸ™ƒ.</p>
<h2 id="genai-model-vs-genai-application-evaluation">GenAI Model vs GenAI Application Evaluation</h2>
<p>In my experience, when people talk about GenAI evaluation, they might not be aware that there is significant difference between GenAI foundation model evaluation and GenAI application evaluation. Both of them are on-going and evolving problems in industry and academia. However, GenAI application evaluation is less talked about comparing to GenAI foundation model evaluation.</p>
<ul>
<li><strong>GenAI foundation model evaluation</strong>: evaluation and benchmarking of foundation models like GPT-4, Dall-E, and Sora, etc.</li>
<li><strong>GenAI application evaluation</strong>:
<ul>
<li>Evaluation and measurement of application enabled by GenAI foundation models like Cursor, a customized call center AI chatbot, etc.</li>
<li>Foundation models are critical part of the GenAI application, but other modules like a vector database or external tools in the application significantly impact the performance of the whole application as well.</li>
</ul>
</li>
</ul>
<p><strong>Not distinguishing the difference between GenAI foundation models and GenAI applications is one of the reasons leading to challenging GenAI application evaluation.</strong> For example, you might use the latest and best LLM model to build a customer service chatbot using a RAG architecture. But if the knowledge base stored in the vector database is not well engineered, I&rsquo;m confident that whole customer service chatbot will underperform your expectation.</p>
<p>There are many academic articles and blogs detailing GenAI foundation model evaluation already. I will link some helpful ones in references section, and focus this article on GenAI application evaluation.</p>
<p>However, as the architecture diagram shown below, a GenAI application is a software application built with GenAI foundation model/models along with other modules. Generally, the objective of a GenAI application is to make end user&rsquo;s life easier by improving their producibility or automate some processes. It usually contains some system logic layer and interface layer. The system logic layer contains internal and external tools, databases, pipeline, and business logic, etc. The interface layer is where the application communicates with the end users. It could be a chatbot UI or command line tool.</p>
<p>To evaluate a GenAI application end to end is to understand:</p>
<ul>
<li><strong>Quantifiable Benefit</strong>: how much incremental gain the application brings to target end users. For example, if an AI coding tool can improve engineers productivity by 50%, it can (ideally) translate to 50% revenue gain.</li>
<li><strong>Isolate and Evaluate</strong>: Build a framework to independently evaluate the performance of each module in the architecture diagram, so that you can identify where the gaps are in the system and improve upon the result.</li>
<li><strong>Cost of adopting GenAI</strong>: Evaluate the operation cost of the GenAI application including engineer effort, external GenAI API cost, human labeller cost, and iteration opportunity cost, etc.</li>
</ul>
<figure class="align-center">
    <a href="GenAI-abstract-architecture.svg" 
       class="glightbox" 
       data-gallery="gallery1" 
       data-title="An abstract architecture of GenAI applications"
       data-type="image"
       data-effect="fade"
       data-zoomable="true">
      <img src="GenAI-abstract-architecture.svg" alt="">
    </a>
    
      <figcaption>An abstract architecture of GenAI applications</figcaption>
    
  </figure>
  
<p>After I explained what GenAI application evaluation entails, I hope you&rsquo;ve realized it&rsquo;s an inherently complex problem. This article aims to demystify the problem.</p>
<h2 id="evaluating-text-image-or-other-media-as-output">Evaluating text, image, or other media as output</h2>
<p>Most classic machine learning problems fall into 2 categories: <strong>Classification</strong> or <strong>Regression</strong>. When we encounter a real world problem, and want to use machine learning to solve it, we usually start with translating the problem to the classic machine learning framework.</p>
<p>Classification and regression have standard evaluation metrics like confusion matrix, accuracy, precision/recall, and R square, etc. If you are interested to read more, please refer to <a href="https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks">ML cheatsheet reference</a>. There are more nuanced derivative metrics for different types of problems like precision@k and <a href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain">NDCG@K</a> for ranking problem. <strong>The classic metrics all share one similarity: they are easily quantifiable via testing set. However, it&rsquo;s not the case for GenAI applications.</strong></p>
<p>For many GenAI applications, their outputs are texts, images, or videos, etc. They are <a href="https://www.mongodb.com/resources/basics/unstructured-data"><strong>unstructured data</strong></a>. On the one hand, the new types of output format are part of GenAI magic. People can easily use natural language to interact with ML/AI technology now. On the other hand, the unstructured data formats make GenAI application evaluation more challenging than traditional ML models. For simplicity, I will use LLM applications as an example to explain it, and outputs of LLM applications are majorly texts.</p>
<p>The following table is a few selected and widely used LLM application metrics with examples. Unlike metrics for classification or regression models, quantifying the LLM metrics is not a simple string comparison or arithmetical calculations. Evaluating metrics like Relevancy, Bias and Hallucination requires a lot of careful design, context understanding and even expertise. For example, if a LLM application is used for medical context, it would be difficult for someone without medical adequate training to evaluate relevancy and hallucination for the application.</p>
<table>
  <thead>
      <tr>
          <th>Metric</th>
          <th>Definition</th>
          <th>Example</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Relevancy</strong></td>
          <td>How on-topic and directly useful the LLM application&rsquo;s output is to a specific task.</td>
          <td>You ask: &ldquo;Marketing slogans for a new eco-friendly water bottle.&rdquo;  <br> <strong>Relevant:</strong> &ldquo;Hydrate Sustainably!&rdquo; <br> <strong>Irrelevant:</strong> &ldquo;The history of plastic manufacturing.&rdquo;</td>
      </tr>
      <tr>
          <td><strong>Bias</strong></td>
          <td>Whether the application outputs biases against certain gender, races or other protected groups.</td>
          <td>You use a LLM application to generate descriptions for job roles. <br> <strong>Bias:</strong> If it consistently describes &ldquo;nurses&rdquo; with feminine pronouns and &ldquo;engineers&rdquo; with masculine pronouns.</td>
      </tr>
      <tr>
          <td><strong>Hallucination</strong></td>
          <td>Whether the LLM application confidently states something as fact that is incorrect, nonsensical, or made-up.</td>
          <td>You ask: &ldquo;What was our company&rsquo;s Q3 revenue last year in the APAC region?&rdquo; <br> <strong>Hallucination:</strong> The LLM replies &ldquo;$5.7 million from our new Tokyo office,&rdquo; when your company has no Tokyo office and revenue was different.</td>
      </tr>
  </tbody>
</table>
<div style="text-align: center; margin-bottom: 20px;">
<strong><em>Table 1: Common evaluation metrics for LLM applications with examples</em></strong>
</div>
<p>Given the complex nature of LLM application evaluation, many people started using LLMs to evaluate output of their LLM application. Many GenAI evaluation packages like <a href="https://www.deepeval.com/">DeepEval</a> and <a href="https://github.com/BCG-X-Official/artkit">ARTKIT</a> offer automated AI evaluation (I have participated in the development of ARTKIT). I do think using LLM to evaluate LLM applications is necessary and helpful, given the amount of output data can be beyond human&rsquo;s capacity to process and LLMs are generally good at language understanding. <strong>However, I think overly relying on LLMs to evaluate LLM application is not realistic and even dangerous.</strong> No matter whether you are using the same family of LLMs to evaluate your LLM application (OpenAI GPTs to evaluate application built on OpenAI GPTs), or using different LLMs to evaluate the LLM application(Google Gemini to evaluate application built on OpenAI GPTs), you are essentially introducing another LLM while evaluating the target LLM application. Would you assume the evaluator LLM&rsquo;s outputs are 100% correct or would you build another evaluation process to evaluate the evaluator LLM? :) The problem become more philosophical now.</p>
<p>I think it&rsquo;s necessary to use LLMs to evaluate LLM applications, but through a carefully design process. I will elaborate on this maybe in another future article.</p>
<h2 id="genai-foundation-models-introduce-unpredictability">GenAI foundation models introduce unpredictability</h2>
<p>Unlike traditional ML models, GenAI models are non-deterministic. It means even for the same input, the GenAI models can return different results on different runs. The non-deterministic nature of GenAI models adds extra difficulty on GenAI application evaluations.</p>
<h3 id="image-generation-example">Image generation example</h3>
<p>For example, I used the same prompt and OpenAI Dall-E 3 to generate 4 images for my cat. And the prompt is</p>
<blockquote>
<p><strong>Pixel art illustration</strong> of a silver-shaded British Shorthair cat playfully fighting with an Amazon Kindle e-reader. The scene is <strong>charming and whimsical</strong>, with the round, fluffy cat using its paws to swipe at or wrestle the sleek Kindle device. Render in detailed 8-bit pixel art style, using cool silver-gray tones for the cat and dark, glossy colors for the Kindle, with a simple, light-colored background.</p></blockquote>
<table>
  <thead>
      <tr>
          <th style="text-align: center"><img loading="lazy" src="/posts/genai-evaluation-challenge/british_shorthair_vs_kindle_2.png" type="" alt="British shorthair vs Kindle 1"  /></th>
          <th style="text-align: center"><img loading="lazy" src="/posts/genai-evaluation-challenge/british_shorthair_vs_kindle_3.png" type="" alt="British shorthair vs Kindle 2"  /></th>
          <th style="text-align: center"><img loading="lazy" src="/posts/genai-evaluation-challenge/british_shorthair_vs_kindle_4.png" type="" alt="British shorthair vs Kindle 3"  /></th>
          <th style="text-align: center"><img loading="lazy" src="/posts/genai-evaluation-challenge/british_shorthair_vs_kindle_5.png" type="" alt="British shorthair vs Kindle 4"  /></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center"><em>image 1</em></td>
          <td style="text-align: center"><em>image 2</em></td>
          <td style="text-align: center"><em>image 3</em></td>
          <td style="text-align: center"><em>image 4</em></td>
      </tr>
  </tbody>
</table>
<p>Among the 4 pixel images, I personally prefer image 2. Image 3 is too realistic and not like a pixel art. The cat in image 4 seems quite concerned and the scene is not charming or whimsical. As for image 1, it&rsquo;s obviously an incoherent image.</p>
<p>Here come the questions for evaluation:</p>
<ul>
<li>How do I evaluate the image outputs?</li>
<li>Should I use the best output (image 2) or worst output (image 1)?</li>
<li>Who&rsquo;s there to evaluate the quality of the outputs?</li>
</ul>
<p>Even the pixel art generation example is trivial itself, the questions regarding evaluation are not trivial. <strong>GenAI models introduce extra unpredictability to your application.</strong></p>
<h3 id="classification-example">Classification example</h3>
<p>Besides generative tasks like image generation above, I&rsquo;ve seen GenAI models applied to classification problems by business. Applying GenAI models to classic ML problems also face challenge from unpredictability in evaluation phase. I created following example based on my observation on how businesses have tried to adopt GenAI applications into their workflow.</p>
<p>A grocery store called Food Coop used to use ML models to classify the category of a new product based on its meta information and description. For example, a new product named &ldquo;cucumber favored Doritos&rdquo; should be classified into &ldquo;Food &gt; Snack Food &gt; Chips&rdquo; category manually or by ML models. Using ML models to process most of new products has saved a lot of manual work from the Food Coop&rsquo;s staff. Recently, the Food Coop started exploring using LLM to classify new product category, meaning giving product taxonomy and new product information and asking LLM to return the most appropriate category for the new product. Suppose the Food Coop&rsquo;s engineer uses the same validation set from previous ML model to test their new LLM classification model, and run the evaluation 10 times on ML models and LLM model, the engineer will get following model score table:</p>
<table>
  <thead>
      <tr>
          <th>Accuracy</th>
          <th>Logistic Regression</th>
          <th>SVM</th>
          <th>LLM classifier</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Round 1</td>
          <td>88%</td>
          <td>91%</td>
          <td>87%</td>
      </tr>
      <tr>
          <td>Round 2</td>
          <td>88%</td>
          <td>91%</td>
          <td>88%</td>
      </tr>
      <tr>
          <td>Round 3</td>
          <td>88%</td>
          <td>91%</td>
          <td>92%</td>
      </tr>
      <tr>
          <td>Round 4</td>
          <td>88%</td>
          <td>91%</td>
          <td>89%</td>
      </tr>
      <tr>
          <td>Round 5</td>
          <td>88%</td>
          <td>91%</td>
          <td>86%</td>
      </tr>
      <tr>
          <td>Round 6</td>
          <td>88%</td>
          <td>91%</td>
          <td>93%</td>
      </tr>
      <tr>
          <td>Round 7</td>
          <td>88%</td>
          <td>91%</td>
          <td>91%</td>
      </tr>
      <tr>
          <td>Round 8</td>
          <td>88%</td>
          <td>91%</td>
          <td>92%</td>
      </tr>
      <tr>
          <td>Round 9</td>
          <td>88%</td>
          <td>91%</td>
          <td>95%</td>
      </tr>
      <tr>
          <td>Round 10</td>
          <td>88%</td>
          <td>91%</td>
          <td>94%</td>
      </tr>
      <tr>
          <td>Average</td>
          <td>88%</td>
          <td>91%</td>
          <td>90%</td>
      </tr>
  </tbody>
</table>
<div style="text-align: center; margin-bottom: 20px;">
<strong><em>Table 2: Accuracy comparison across multiple evaluations for ML models vs LLM classifier</em></strong>
</div>
<p>The accuracy stays consistent for logistic regression model and SVM, since they are deterministic models and the validation set is unchanged through out 10 rounds. However, the accuracy of LLM classifier fluctuates over time. The fluctuating acc</p>
<p><strong>How should the Food Coop compare the new LLM classifier with traditional ML models for this classification task?</strong></p>
<p>In theory, the Food Coop needs to model accuracy of LLM classifier as:</p>
<p><code>Observed accuracy = Accuracy + variance of the LLM application</code></p>
<p>In practice, the Food Coop might compare average accuracy of the 3 models and decide the SVM model preforms better than the LLM classifier. However, this is not an ideal approach since many businesses are required to provide expandability to their model outcomes.</p>
<h3 id="new-bias-variance-paradigm">New bias-variance paradigm</h3>
<p><a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">The bias-variance tradeoff</a> is a classic paradigm in supervised machine learning. One of major tasks of ML evaluation is to find the optimal model complexity for a ML problem. The image below is a text-book visualization of the paradigm.</p>
<figure class="align-center">
    <a href="Bias_and_variance_contributing_to_total_error.png" 
       class="glightbox" 
       data-gallery="gallery1" 
       data-title="Bias and variance as function of model complexity"
       data-type="image"
       data-effect="fade"
       data-zoomable="true">
      <img src="Bias_and_variance_contributing_to_total_error.png" alt="">
    </a>
    
      <figcaption>Bias and variance as function of model complexity</figcaption>
    
  </figure>
  
<div style="text-align: center; margin-bottom: 20px;">
<em>Image by Bigbossfarin - Own work, CC0, via <a href="https://commons.wikimedia.org/w/index.php?curid=105307219">Wikimedia Commons</a></em>
</div>
<p>However, when GenAI applications are introduced to the paradigm, I think the visualization should be updated as following:
<figure class="align-center">
    <a href="new_bias_variance_paradigm.png" 
       class="glightbox" 
       data-gallery="gallery1" 
       data-title="Updated bias and variance as function of model complexity"
       data-type="image"
       data-effect="fade"
       data-zoomable="true">
      <img src="new_bias_variance_paradigm.png" alt="">
    </a>
    
      <figcaption>Updated bias and variance as function of model complexity</figcaption>
    
  </figure>
  </p>
<p>The purple interval around the total error means total error is not a fixed number based on variance and bias anymore, the unpredictability(variance) of GenAI model makes the total error fluctuate within the interval. In Table 2 example, the purple interval represents the variance of accuracy of the same LLM classifier.</p>
<p>By comparing the two paradigms, I hope the complexity of GenAI application evaluation is more clear to you.</p>
<h2 id="genai-application-evaluation-is-expensive-and-time-consuming">GenAI application evaluation is expensive and time consuming</h2>
<p>Besides the complexities elaborated above, building an proper process to evaluate a GenAI application is also expensive and time consuming.</p>
<p>The best practice of developing a machine learning system is to start from proof-of-concept and built towards <a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning">continuous delivery and automation pipelines</a> over time. The same framework can be adopted to GenAI application as well. <strong>The modern MLOps practice requires you to test your application on data, improve your application, generate new test data, and iterate the process rapidly.</strong> If one iteration of evaluation is costly and slow, continuous iteration is naturally challenging.</p>
<h3 id="evaluation-dataset-building">Evaluation dataset building</h3>
<p>However, generating evaluation dataset or golden dataset for GenAI application and iterating on it is more complex than previous ML systems. For example, if you want to build an effective GenAI Q&amp;A system, you have to build a list of golden Q&amp;A dataset to test your system. Curating a high-quality golden Q&amp;A dataset is significantly more difficult than labelling objects on an images, because reading texts requires more time and context understanding. Sometimes, only certain people with expertise are capable of curating a golden Q&amp;A dataset, and the task cannot be out sourced to internal or external data labelers.</p>
<p>Therefore, building proper an evaluation dataset for a GenAI application and updating the dataset can be expensive and slow.</p>
<h3 id="evaluation-cost">Evaluation cost</h3>
<p>Even when a good evaluation dataset is built, running tests on it can be challenging. Conventionally, training a ML model can take long time and considerably amount of resources, but inference on the trained model is fast and cheap. However, when evaluating a GenAI application built upon a 3rd party foundation model provider, you will encounter:</p>
<ul>
<li>
<p><strong>API latency</strong>: GenAI foundation model APIs typically have much higher latency than traditional ML model inference. While a conventional ML model might return results in milliseconds, GenAI APIs can take seconds or even minutes for complex prompts. This latency significantly slows down the evaluation process, especially when testing hundreds or thousands of examples.</p>
</li>
<li>
<p><strong>API rate limit</strong>: Most foundation model providers impose strict rate limits on their APIs to manage server load and prevent abuse. These rate limits force you to implement complex batch processing, asynchronous logic, queuing mechanisms, and retry logic in your evaluation pipeline. You may need to spread your evaluation over longer periods or request (and pay for) higher rate limits, further extending the time and cost of thorough testing.</p>
</li>
<li>
<p><strong>API cost</strong>: Even though LLM like GPT4 has decreased significantly, it is still very costly comparing to traditional ML like OCR. Especially, when the input and output of the system contain large size of texts or high-resolution images, the cost of running tests continuously is not economically wise.</p>
</li>
</ul>
<p>Hosting an open-source GenAI foundation model might help you avoid API related issue, but it still requires intense resources and expertise. You might finding your organization spending more money and time on cloud resources and debugging its configuration than using an API from a foundation model provider.</p>
<h2 id="conclusion">Conclusion</h2>
<h2 id="references">References</h2>
<ul>
<li><a href="https://www.anthropic.com/news/evaluating-ai-systems">Anthropic&rsquo;s guide on GenAI foundation model evaluation</a>: Anthropic shared the challenging they&rsquo;ve faced when evaluating GenAI models.</li>
<li><a href="https://arxiv.org/abs/2311.02462">Levels of AGI for Operationalizing Progress on the Path to AGI</a> <!-- tbd --></li>
<li><a href="https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks">ML metrics cheatsheet by Stanford</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Rebuild My Website With GenAI&#39;s Assistance</title>
      <link>http://localhost:49602/posts/blog-set-up/</link>
      <pubDate>Tue, 29 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:49602/posts/blog-set-up/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When I was in graduate school, I set up a &lt;a href=&#34;https://gytcrt.github.io/&#34; rel=&#34;noopener&#34; target=&#34;_blank&#34;&gt;personal blog&lt;/a&gt; to showcase my project and share thoughts. I planned to keep developing that site but it has since then taken a backseat while I became busy with work.&lt;/p&gt;
&lt;p&gt;I have got more time lately and decided to pick up this project. It turned out to be so much fun, and I want to share how I have re-built this website with GenAI tools. &lt;strong&gt;If you are only interested in the part related to GenAI, check out the &lt;a href=&#34;http://localhost:1313/posts/blog-set-up/#genai-coding-tools-cursor--dall-e-3--runway--llms&#34;&gt;&lt;strong&gt;GenAI coding tools section&lt;/strong&gt;&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>When I was in graduate school, I set up a <a href="https://gytcrt.github.io/" rel="noopener" target="_blank">personal blog</a> to showcase my project and share thoughts. I planned to keep developing that site but it has since then taken a backseat while I became busy with work.</p>
<p>I have got more time lately and decided to pick up this project. It turned out to be so much fun, and I want to share how I have re-built this website with GenAI tools. <strong>If you are only interested in the part related to GenAI, check out the <a href="http://localhost:1313/posts/blog-set-up/#genai-coding-tools-cursor--dall-e-3--runway--llms"><strong>GenAI coding tools section</strong></a>.</strong></p>
<h2 id="choosing-and-registering-a-domain-name">Choosing and registering a domain name</h2>
<p>Choosing a domain name is like choosing a <a href="https://www.shopify.com/blog/domain-seo?term=&amp;adid=647967866337&amp;campaignid=19683492884&amp;utm_medium=cpc&amp;utm_source=google&amp;gad_source=1&amp;gclid=CjwKCAjwwqfABhBcEiwAZJjC3poWT02q2-7_BJRlCqsvGTnMw5UM1d8tee_OgW0UnffVvSXugolTdBoClrwQAvD_BwE#" rel="noopener" target="_blank">brand name</a> for your website. Luckily, I don&rsquo;t share a name with any celebrities or public figures. I was initially able to register for andreagao.com in 2017 via Google Domain, and generally had a good experience using the service. But unfortunately, they have been <a href="https://www.theverge.com/2023/6/16/23763340/google-domains-sunset-sell-squarespace" rel="noopener" target="_blank">acquired by Squarespace</a>. So I had to find another domain registrar.</p>
<p>I quoted on both <a href="https://aboutus.godaddy.net/about-us/overview/default.aspx" rel="noopener" target="_blank">GoDaddy</a> and <a href="https://www.namecheap.com/" rel="noopener" target="_blank">Namecheap</a>, and figured the price on Namecheap is more sensible to me. From a usability standpoint, I think Namecheap is comparable to Google Domain.</p>
<p>If you are thinking about obtaining a domain for your own website, you can also check out this helpful <a href="https://www.reddit.com/r/webdev/comments/1bjfqse/whats_the_best_domain_registrar_in_2024/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noopener" target="_blank">Reddit thread</a> on the best domain registrars in 2024.</p>
<h2 id="framework-selection">Framework selection</h2>
<p>There are millions of ways to build a personal website in 2025. If you are inclined to avoid coding and deploying front-end, <a href="https://www.wix.com/" rel="noopener" target="_blank">Wix</a>, <a href="https://wordpress.com/" rel="noopener" target="_blank">Wordpress</a> and <a href="https://www.squarespace.com/" rel="noopener" target="_blank">Squarespace</a> are all classic options. Or you can consider a GenAI website builder like <a href="https://replit.com/" rel="noopener" target="_blank">replit</a> too.</p>
<p>I decided to use a <a href="https://en.wikipedia.org/wiki/Static_site_generator" rel="noopener" target="_blank">static website builder</a>, since I want to code more and have more control over my website. Like the no-code options in the last paragraph, there are many static website builder frameworks too. <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo</a> and <a href="https://jekyllrb.com/" rel="noopener" target="_blank">Jekyll</a> are the most popular ones. Compared to Jekyll, Hugo is younger and faster. I used Jekyll to build my previous website, so I thought it would be interesting to explore Hugo. For anyone who wants to try a static website builder, I recommend either. There are a lot of templates and resources available online for both of them. You cannot go wrong either way.</p>
<p>Both Hugo and Jekyll provide a lot of themes (like a PPT template) for you to build upon. Here are two good resources for finding themes:</p>
<ul>
<li>Jekyll themes: <a href="https://jekyllthemes.io/jekyll-portfolio-themes">https://jekyllthemes.io/jekyll-portfolio-themes</a></li>
<li>Hugo themes: <a href="https://themes.gohugo.io/tags/blog/">https://themes.gohugo.io/tags/blog/</a></li>
</ul>
<p><strong>I also found it very helpful to browse the themes as used on other people&rsquo;s websites.</strong> Some of them serve as a great inspiration for me, and many folks wrote blogs about their website set-up and customization.</p>
<p>After browsing over a hundred websites, I picked <a href="https://reorx.github.io/hugo-PaperModX/" rel="noopener" target="_blank">PaperModX</a> for my own. PaperModX is an enhanced version of <a href="https://adityatelange.github.io/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>. I like the clean aesthetic of the theme, and it is the <a href="https://github.com/QIN2DIM/awesome-hugo-themes" rel="noopener" target="_blank">top starred GitHub theme</a> for Hugo. <strong>Similar to other design choices in software development, choosing a popular framework with a mature community makes your life easier.</strong></p>
<h2 id="hosting-and-deployment-github-pages--github-actions">Hosting and deployment: Github Pages + Github Actions</h2>
<p>Since I&rsquo;m building a static website, which contains no dynamic content, the best and most economical place to host it is <a href="https://pages.github.com/" rel="noopener" target="_blank">Github pages</a>. It is free if you are using a public repo or some premium version of Github account.</p>
<p>In addition, <a href="https://github.com/features/actions" rel="noopener" target="_blank">Github Actions</a> has made deployment very easy along with Github Pages. Hugo has a page on <a href="https://gohugo.io/host-and-deploy/host-on-github-pages/" rel="noopener" target="_blank">hosting on Github Pages with Github Actions</a>. I recommend following the page to deploy your static website.</p>
<p><strong>If you are not familiar with deployment or CI/CD tools like Github Actions, don&rsquo;t be scared by it. With Github Copilot and AI coding tools like Cursor, configuring the deployment files is now way easier than it used to be.</strong></p>
<h2 id="analytics-set-up-umami--digitalocean">Analytics set up: Umami + DigitalOcean</h2>
<p>In modern product/software development, feedback is essential for improvement. My website aims to serve both myself and my audience, so I&rsquo;d love to take feedback from readers. In this section, I will talk about my analytics platform set up.</p>
<p>Hugo PaperMod provides very easy integration with <a href="https://support.google.com/analytics/answer/10089681?hl=en" rel="noopener" target="_blank">Google Analytics 4</a>. I believe using Google Analytics would be the most straightforward and time-saving set up. However, I do want to have more control over my traffic data, so I did more research on potential analytics tools. <a href="https://plausible.io/" rel="noopener" target="_blank">Plausible Analytics</a> and <a href="https://umami.is/" rel="noopener" target="_blank">Umami</a> are two of the popular tools. I picked Umami since it&rsquo;s open-source, free, and self-hostable.</p>
<p>As for hosting, I prefer minimal setup and effort for Umami, since it&rsquo;s an internal tool for my website and I don&rsquo;t have billions of visitors. I chose DigitalOcean to host my Umami server and managed database. DigitalOcean provides a very <a href="https://www.digitalocean.com/community/tutorials/how-to-install-umami-web-analytics-software-on-ubuntu-20-04" rel="noopener" target="_blank">detailed tutorial</a> on setting up Umami on its Ubuntu machine. I found it almost effortless to set up Umami on DigitalOcean.</p>
<figure class="align-center ">
    <img loading="lazy" src="umami.png#center"
         alt="Umami dashboard for a day&#39;s visit"/> <figcaption>
            <p>Umami dashboard for a day&rsquo;s visit</p>
        </figcaption>
</figure>

<h2 id="genai-coding-tools-cursor--dall-e-3--runway--llms">GenAI coding tools: Cursor + Dall-E 3 + Runway + LLMs</h2>
<p><strong>TL;DR:</strong></p>
<ul>
<li><strong>Choose the right tools for you:</strong> for anyone considering using a GenAI IDE, I recommend checking out the latest discussions online and experimenting a bit with different IDEs and models. Pick the one you like the most.</li>
<li><strong>Programming skills are still valuable:</strong> for anyone considering a non-trivial project, it&rsquo;s important to master one programming language and know the fundamentals of the language in which you are programming. <a href="https://www.deeplearning.ai/the-batch/issue-298/" rel="noopener" target="_blank">Andrew Ng&#39;s recent post</a> gives an in-depth breakdown of what this means for developers.</li>
<li><strong>GenAI enhances creativity:</strong> using image generation and video generation models to create visual content is amazing!</li>
</ul>
<hr>
<p>I majored in mathematics and statistics in undergrad and graduate school, respectively, and my major programming languages back then were Matlab and R. When I built my first website with Python and Jekyll, it was challenging to pick up a new framework by myself.</p>
<p>I&rsquo;m so grateful for the wide range of GenAI coding tools available in 2025. GenAI coding tools plus LLMs have made solo web development experience significantly easier this time. <strong>Cursor and other GenAI tools free me from typing code, and allow me to focus on all aspects of design: including system design, web design, and UX design.</strong></p>
<p>Therefore, I want to detail my experience using GenAI tools for this website. This section is not meant to be a comprehensive review of GenAI coding tools, which will be the subject of a separate article I plan to write.</p>
<h3 id="ide">IDE</h3>
<p>I have heard from friends and online communities that Cursor + Claude is the best GenAI IDE in the market at this moment. Nevertheless, I looked into other options too.</p>
<h4 id="replit-ai-app-builder">Replit: AI app builder</h4>
<p><a href="https://replit.com/" rel="noopener" target="_blank">Replit</a> is like a no-code GenAI based app builder platform, and it allows the user to use natural language prompts to build. You can use it as an IDE if you have to access terminal and code.</p>
<p>I experimented with Replit for a couple of hours. I asked it to build a personal website based on Hugo PaperModX theme. <strong>I think someone without coding skills might be able to build a decent static website in Replit with more time.</strong> For people with programming experience, a GenAI Editor makes more sense.</p>
<h4 id="traeai">Trae.ai</h4>
<p><a href="https://www.trae.ai/" rel="noopener" target="_blank">Trae.ai</a> is a free GenAI editor, which provides unlimited free access to Claude 3.7 Sonnet model. This sounds particularly attractive in comparison to Cursor, which requires a $20 monthly subscription.</p>
<p>However, as an old (internet) saying goes, &ldquo;when a product is free, you are the product.&rdquo; If you carefully read <a href="https://www.trae.ai/privacy-policy" rel="noopener" target="_blank">Trae.ai&#39;s privacy policy</a> (or ask a LLM to summarize it for you), you can infer that they retain the right to collect any information and code to potentially use for model training. Here are two quotes from the policy:</p>
<blockquote>
<p>When you interact with the Platform&rsquo;s integrated AI-chatbot, we collect any information (including any code snippets) that you choose to input.</p></blockquote>
<blockquote>
<p>To review, improve, and develop the Platform, including by analyzing how you are using the Platform, conducting voluntary surveys and research, and training and improving our technology.</p></blockquote>
<p>I didn&rsquo;t feel comfortable with these terms, and decided to not try it.</p>
<h4 id="cursor">Cursor</h4>
<p>Before I started using <a href="https://www.cursor.com/" rel="noopener" target="_blank">Cursor</a>, I tried other GenAI coding tools like Github copilot, Colab with Gemini, etc. But Cursor is a game changer for me, and I&rsquo;m paying the $20 monthly subscription for it. It means a lot since I&rsquo;m a person with no Amazon Prime account ðŸ™‚.</p>
<p>I&rsquo;ve been using Cursor + <code>Claude-3.5/3.7-sonnet</code> while developing this website. In my experience, <code>Claude-3.7-sonnet</code> and <code>Claude-3.7-sonnet-thinking</code> perform better than <code>Claude-3.5</code>. But I don&rsquo;t recommend sticking to this config if you are considering using Cursor. The development of LLM moves so fast that my current experience won&rsquo;t be relevant in three months.</p>
<p>For anyone considering using a GenAI IDE, I recommend checking out the latest discussions on this online and experimenting a bit with different IDEs and models. Pick the one that best fits your needs.</p>
<p>Regarding privacy and data usage, I found <a href="https://www.cursor.com/privacy" rel="noopener" target="_blank">Cursor&#39;s privacy policy</a> to be reasonable, and keep &ldquo;Privacy Mode&rdquo; enabled while using the editor.</p>
<h3 id="image-and-video-generation">Image and video generation</h3>
<p>I always spend tons of time on choosing the best images for my post. Using a GenAI model to create images or videos for my website has been a great experience for me.</p>
<p>I wanted some art on the landing page that was relevant to both the website and my interests on the landing page. It occurred to me that something labyrinthian and retro-futuristic would be fitting: someone can only walk randomly in a labyrinth and I love the aesthetic of movies like <a href="https://www.imdb.com/title/tt0081505/" rel="noopener" target="_blank">The Shining</a> and <a href="https://www.imdb.com/title/tt0083658/?ref_=fn_all_ttl_1" rel="noopener" target="_blank">Blade Runner</a>.</p>
<p>Initially, I wanted to use GenAI to create some pixel art versions of nostalgic screensavers like the GIF below. When I was a kid, I could watch these animations for a long time. <a href="https://www.theparisreview.org/blog/2017/05/23/salvation-mode/" rel="noopener" target="_blank">And I am not alone in this fascination</a>!</p>
<figure class="align-center ">
    <img loading="lazy" src="maze_animation.gif#center"
         alt="90s Windows 3D Maze ScreenSaver"/> <figcaption>
            <p>90s Windows 3D Maze ScreenSaver</p>
        </figcaption>
</figure>

<p>The outcomes of my first few attempts were not ideal. So I pivoted to another idea: <strong>a pixel art of a Hong Kong street</strong>. Hong Kong is my favorite city and it is an iconic retro-futuristic symbol. Hong Kong itself is a maze, as seen in film settings like <a href="https://en.wikipedia.org/wiki/Chungking_Express" rel="noopener" target="_blank">Chungking Express</a>.</p>
<p>I used GPT 4.0 to generate some prompts, and input the prompts to Dall-E 3 for image generation. Here are selected outputs from Dall-E 3:</p>
<table>
  <thead>
      <tr>
          <th style="text-align: center"><img loading="lazy" src="/posts/blog-set-up/Hong_Kong_night_scene_1.gif" type="" alt="Hong Kong night scene 1"  /></th>
          <th style="text-align: center"><img loading="lazy" src="/posts/blog-set-up/Hong_Kong_night_scene_2.png" type="" alt="Hong Kong night scene 2"  /></th>
          <th style="text-align: center"><img loading="lazy" src="/posts/blog-set-up/Hong_Kong_night_scene_3.png" type="" alt="Hong Kong night scene 3"  /></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center"><em>Hong Kong night scene 1</em></td>
          <td style="text-align: center"><em>Hong Kong night scene 2</em></td>
          <td style="text-align: center"><em>Hong Kong night scene 3</em></td>
      </tr>
  </tbody>
</table>
<p>I really love the pixel arts Dall-E 3 created for me. Here is the prompt I used:</p>
<blockquote>
<p>Minimalist pixel art of a Hong Kong street at night for a personal website landing page, with simple, blocky buildings and glowing neon signs in pink, blue, and yellow. The scene has a dark background and features small pixel art people walking on the sidewalks and a few cars on the street. Use an 8-bit retro style with clean lines and minimal details. Leave open space at the top for a website title.</p></blockquote>
<p>After I had the pixel arts, I felt very pleased by the progress already. However, I went along and tried to animate the pixel art into GIF using GenAI tools. I tried two popular AI video generation tools: <a href="https://www.kaiber.ai/superstudio" rel="noopener" target="_blank">Kaiber</a> and <a href="https://runwayml.com/" rel="noopener" target="_blank">Runway</a>. Kaiber is not intuitive to use and I was not able to generate a video with the trial credits for a new user. However, I found Runway to be quite impressive and I really like the animated video it produced, seen below. This gif is my landing page cover picture now.</p>
<figure class="align-center ">
    <img loading="lazy" src="/images/day_scene_optimized.gif#center"
         alt="Animated Hong Kong street scene pixel art"/> <figcaption>
            <p>Animated Hong Kong street scene pixel art</p>
        </figcaption>
</figure>

<h3 id="llms-openai--gemini">LLMs: OpenAI + Gemini</h3>
<p>Besides Cursor + <code>Claude-3.5/3.7-sonnet</code>, I still use other LLMs including <code>Gemini 2.5 Pro</code> and <code>GPT-4</code> to help with my development, considering:</p>
<ul>
<li><strong>Price/Value:</strong> Compared to using limited premium models with a request quota on Cursor, those LLMs are free. I can reserve my quota to more important questions that require access to my codebase.</li>
<li><strong>Guide code from AI with second opinion:</strong> None of the GenAI tools or LLMs are a silver bullet for coding. Code from LLM can be very redundant, and lacks holistic design consideration. I found it critical to use my own engineering experience to direct the development process and take a second opinion from friends or another LLM/GenAI system.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>It has been an interesting journey for me to restart an old project and reflect on my current process. AI tools have totally changed how I code, but they still require guidance and creativity at this moment. Like any other pivotal moment in history, it could be scary or exciting; but it will certainly bring about major changes. I will continue to use this website to log the changes.</p>
<h2 id="features-in-backlog">Features in backlog</h2>
<ul>
<li><input disabled="" type="checkbox"> Enable comments section</li>
<li><input disabled="" type="checkbox"> Add an archive tag</li>
<li><input disabled="" type="checkbox"> Add buttons to share to social media</li>
<li><input disabled="" type="checkbox"> Other advice?</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>A Random Walk</title>
      <link>http://localhost:49602/posts/random-walk/</link>
      <pubDate>Sat, 19 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:49602/posts/random-walk/</guid>
      <description>&lt;p&gt;I chose &amp;ldquo;Random Walk&amp;rdquo; as the name of my website, as both a representation of my work and personal interests.&lt;/p&gt;
&lt;p&gt;Randomness is prominent in the fields of modern statistical theory, machine learning, and AI (Deep Learning). In recent years, the unpredictability of the Large Language Model(LLM) has presented a  major challenge for companies and individuals looking to adopt the latest AI in their business and daily life. However, I think randomness brings a lot of opportunities and beauty to the world, too.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>I chose &ldquo;Random Walk&rdquo; as the name of my website, as both a representation of my work and personal interests.</p>
<p>Randomness is prominent in the fields of modern statistical theory, machine learning, and AI (Deep Learning). In recent years, the unpredictability of the Large Language Model(LLM) has presented a  major challenge for companies and individuals looking to adopt the latest AI in their business and daily life. However, I think randomness brings a lot of opportunities and beauty to the world, too.</p>
<p>An example of this is my own process of debugging a technical issue: sometimes, I may think of a few potential solutions, but I don&rsquo;t yet know which one is optimal. I might randomly proceed with one of the ideas if they all look viable to me. If it doesn&rsquo;t work, I would roll back to the previous version and try another approach. Random seeds(np.random.seed(1234)ðŸ˜‰) or random experiments can lead to solutions and innovations.</p>
<p>When I was a teenager, I was fascinated by <a href="https://en.wikipedia.org/wiki/Jorge_Luis_Borges" rel="noopener" target="_blank">Jorge Luis Borges</a>&rsquo;s short novel <a href="https://mycours.es/gamedesign2012/files/2012/08/The-Garden-of-Forking-Paths-Jorge-Luis-Borges-1941.pdf" rel="noopener" target="_blank">The Garden of Forking Paths</a>. The novel is very mysterious, multidimensional, and intriguing. It visualizes our life (or world) as a giant labyrinth; whenever we make a decision, it leads to one of life&rsquo;s paths. In a way, it&rsquo;s similar to Github forking and branching. Do all paths converge to the same global optimal like random walk in <a href="https://people.duke.edu/~ccc14/sta-663/mcmc.html" rel="noopener" target="_blank">Markov chain Monte Carlo method</a>? Or is my existence and selfhood only one of many in an infinite number of universes?</p>
<figure class="align-center ">
    <img loading="lazy" src="gitflow.svg#center"
         alt="A Gitflow visualization"/> <figcaption>
            <p>A Gitflow visualization</p>
        </figcaption>
</figure>

<p>I appreciate the ways in which theory, engineering, and art converge upon &ldquo;Random Walk.&rdquo; I hope you enjoy a short walk on my site.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>My Second Post</title>
      <link>http://localhost:49602/posts/my-second-post/</link>
      <pubDate>Thu, 17 Apr 2025 13:40:47 -0400</pubDate>
      
      <guid>http://localhost:49602/posts/my-second-post/</guid>
      <description>&lt;p&gt;This is a test link: &lt;a href=&#34;https://www.prospectpark.org/&#34;&gt;Prospect Park&lt;/a&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>This is a test link: <a href="https://www.prospectpark.org/">Prospect Park</a>.</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
